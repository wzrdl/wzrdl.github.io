# 1. 什么是Language Model

LM是在建模token的PDF，我们会记作：$P(x_1​,…,x_T​)$，对于在$i$位置上的token，我们可以用另一只表示形式：$P(x_i | x_{<i})$ 意思是基于给定的token，这个位置的概率分布。LM的目的就是在给定的情况下，某一个位置的词(token)的概率。

# 2. 什么是自回归模型(Autoregressive Model)？

自回归模型就是把整句token的联合概率，用链式法则拆成一串“next token prediction"的条件概率，我们通常用：
$$
P(x_1,x_2,...,x_T) = \prod_{t=1}^T P(x_t | x_{<t})
$$

# 3. 为什么要用用自回归分解？

直接在高维空间上建模整句的联合分布太难了，自回归模型将这个巨大的问题拆分成多个局部的问题，每次只关注一个位置的条件概率，这样训练和实现都比较简单

# 4. 什么是LLM的温度？

LLM的温度是在